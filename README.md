# Data Science Portfolio

Portfolio including my data science projects for Kaggle competitions and self-learning.

More information about me: [LinkedIn](https://www.linkedin.com/in/shanmugam-marimuthu-771aa818a/)


## <p>Projects

* **[University of Liverpool - Ion Switching](https://github.com/shanmugamm212/Data-Science-Portfolio/blob/master/University%20of%20Liverpool%20-%20Ion%20Switching.ipynb)**: Machine Learning project to predict the number of open ion channels based on electrophysiological signals from human cells.
    * Created custom architecture Using Gated Recurrent Unit, Linear layer followed by activation functions.
Further increased accuracy by hyper-parameter tuning.
    * Experimented with Kaiming initialization and used KFold for model selection.
    * The final model predicted the number open channels for a signal with 93.7% accuracy.

* **[M5 Forecasting - Accuracy](https://github.com/shanmugamm212/Data-Science-Portfolio/blob/master/M5%20Forecasting%20-%20Accuracy.ipynb)**: Kaggle project to forecast unit sales of various products sold in USA by
Walmart, in collaboration with University of Nicosia.
    * Experimented with Random Forest, Deep neural network - fully connected, RNN for same dataset.
    * The final model with WRMSSE of 0.75.
    
* **[Real or Not? NLP with Disaster Tweets](https://github.com/shanmugamm212/Data-Science-Portfolio/blob/master/Real%20or%20Not%3F%20NLP%20with%20Disaster%20Tweets.ipynb)**: Natural Language Processing project comprising of:
    * Transfer Learning is used to get the pretrained weights and vocabularies from language model, combined
withtweet dataset and used AWD LSTM Architecture.
    * Accuracy evaluated by F1. Got 79% accuracy

* **[Language Model - Tamil](https://github.com/shanmugamm212/Data-Science-Portfolio/blob/master/Language%20Model%20-%20Tamil.ipynb)**: Machine Learning project to create pretrained language model for the language Tamil.
    * Used Wikipedia Dataset. Trained model with Pytorch framework using FastAI APIâ€™s.
    * This model is used to predict the next word by learning from Wikipedia data.
